{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB-p10JxI8no"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "14G79Q65kOOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "start = time.time()\n",
        "# Loading the dataset\n",
        "(data, labels),_ = cifar10.load_data()\n",
        "end = time.time()\n",
        "print(f'Dataset loaded in {round(end-start,2)} seconds')\n",
        "\n",
        "c10 = {'data': data, 'target': labels}\n",
        "\n",
        "# Printing dataset overview\n",
        "samples = c10['data'].shape[0]\n",
        "features_per_sample = c10['data'].shape[1:]\n",
        "classes = len(set(c10['target'].flatten()))\n",
        "\n",
        "print(f'Samples : {samples}')\n",
        "print(f'Features per sample : {features_per_sample}')\n",
        "print(f'Classes : {classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3M0kCT3JZYp",
        "outputId": "a50ae014-4c8f-4311-d381-3023615b4fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded in 1.2725331783294678 seconds\n",
            "Samples : 50000\n",
            "Features per sample : (32, 32, 3)\n",
            "Classes : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization and Flattening"
      ],
      "metadata": {
        "id": "_RTifVVlkTuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Normalization of data between 0 and 1\n",
        "c10['data'] = c10['data'].astype('float32') / 255.0\n",
        "\n",
        "# Flattening of images\n",
        "c10['data'] = c10['data'].reshape(samples, -1)\n",
        "\n",
        "# Dataset overview after flattening\n",
        "features_per_sample = c10['data'].shape[1]\n",
        "print(f'Samples : {samples}')\n",
        "print(f'Features per sample : {features_per_sample}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNPwcG_9Ks-L",
        "outputId": "b108ebde-d9ba-4597-cf67-700d0f7d4a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples : 50000\n",
            "Features per sample : 3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting HoG(Histogram of Oriented Gradients) features"
      ],
      "metadata": {
        "id": "CgftAfFzkZPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "hog_features = []\n",
        "\n",
        "# Function to compute hog features of every image\n",
        "start = time.time()\n",
        "\n",
        "for image in c10['data']:\n",
        "  image = image.reshape((32,32,3))\n",
        "  gray_scaled_image = rgb2gray(image)\n",
        "  # finding the hog vector from gray-scaled image\n",
        "  hog_vector = hog(gray_scaled_image,orientations = 9,pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=False,multichannel=False)\n",
        "  hog_features.append(hog_vector)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f'Extraction completed in {round(end-start,2)} seconds')\n",
        "c10_hog_features = np.array(hog_features)\n",
        "\n",
        "print(f'Samples : {c10_hog_features.shape[0]}')\n",
        "print(f'Features per sample : {c10_hog_features.shape[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe27QGCYLhu6",
        "outputId": "2ef8860e-90c4-42e5-f797-0ade618c4abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed in 44.72910761833191 seconds\n",
            "Samples : 50000\n",
            "Features per sample : 324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test Split (80:20)"
      ],
      "metadata": {
        "id": "M6J9_YHlkpam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting into training and testing data\n",
        "X_train,X_test,y_train,y_test = train_test_split(c10_hog_features,c10['target'],train_size=0.8,random_state=42)\n",
        "\n",
        "print(f'Size of training data : {X_train.shape}')\n",
        "print(f'Size of testing data : {X_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npumeDnpNCEJ",
        "outputId": "7f5a0783-3cea-4ddd-ba2b-c0554f1ef9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data : (40000, 324)\n",
            "Size of testing data : (10000, 324)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Classifiers with different kernels"
      ],
      "metadata": {
        "id": "7nYUu7xUkxht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# different kernels for SVC\n",
        "kernels = ['linear','poly','rbf','sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "  start = time.time()\n",
        "  clf = SVC(kernel=kernel)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  end = time.time()\n",
        "  print(f'For kernel {kernel}, accuracy : {accuracy} Completed in {round(end-start,2)} seconds')"
      ],
      "metadata": {
        "id": "BWQQXDtgNgTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search for hyperparameter tuning on RBF(Radial Basis Function) kernel"
      ],
      "metadata": {
        "id": "BjwSjO45k25j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# set of values of 'C' and 'gamma'\n",
        "hyperparameters = {'C':[0.1, 1, 10, 100],\n",
        "                    'gamma': [0.001, 0.01, 0.1, 1, 10]}\n",
        "\n",
        "rbf_clf = SVC(kernel='rbf')\n",
        "\n",
        "# performing grid search\n",
        "grid_search = GridSearchCV(rbf_clf, hyperparameters, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# best set of 'C' and 'gamma'\n",
        "print(f'The ideal hyperparameters are : {grid_search.best_params_}')\n",
        "\n",
        "print(f'Cross validation accuracy : {grid_search.best_score_}')\n",
        "\n",
        "# prediction using the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy after hyper-parameter tuning : {accuracy}')"
      ],
      "metadata": {
        "id": "xYD0LKNYOYHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}